{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQgeMQk-tsRE"
      },
      "source": [
        "# Import libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KWhHtGegLL3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from langdetect import detect\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
        "\n",
        "from datasets import Dataset\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from transformers import EarlyStoppingCallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hD-3M2v1hF6f"
      },
      "outputs": [],
      "source": [
        "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvJ0gVGY-blS"
      },
      "source": [
        "# Data loading and dataframe construction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iu3Qjhjjj-d-"
      },
      "outputs": [],
      "source": [
        "folder_path='/content/drive/MyDrive/Colab Notebooks/code_classification_dataset'\n",
        "data_list=[]\n",
        "\n",
        "for filename in os.listdir(folder_path):\n",
        "    filepath=os.path.join(folder_path, filename)\n",
        "    with open(filepath, 'r') as f:\n",
        "        data=json.load(f)\n",
        "        data_list.append(data)\n",
        "\n",
        "df=pd.DataFrame(data_list)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBUlXHNx_g9r"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_O3h-a4kNol"
      },
      "outputs": [],
      "source": [
        "# Delete all tags we aren't trying to predict\n",
        "tags_to_keep=['math', 'graphs', 'strings', 'number theory', 'trees', 'geometry', 'games', 'probabilities']\n",
        "df['tags']=df['tags'].apply(lambda taglist: [tag for tag in taglist if tag in tags_to_keep])\n",
        "\n",
        "# Multilabel binarization\n",
        "mlb=MultiLabelBinarizer(classes=tags_to_keep)\n",
        "y=pd.DataFrame(mlb.fit_transform(df['tags']), columns=mlb.classes_)\n",
        "y=y.astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Deleting rows with non english descriptions\n",
        "def is_english(text):\n",
        "    try:\n",
        "        return detect(text)=='en'\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "english_mask=df['prob_desc_description'].apply(is_english)\n",
        "df=df[english_mask]\n",
        "y=y[english_mask]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6g1YCshm_pDq"
      },
      "outputs": [],
      "source": [
        "# Identification of the examples with no tags\n",
        "no_tag_mask=(y.sum(axis=1)==0)\n",
        "\n",
        "# Undersampling examples with none of the eight tags\n",
        "no_tag_df=df[no_tag_mask].sample(frac=0.4, random_state=42)\n",
        "no_tag_y=y[no_tag_mask].loc[no_tag_df.index]\n",
        "\n",
        "with_tag_df=df[~no_tag_mask]\n",
        "with_tag_y=y[~no_tag_mask]\n",
        "\n",
        "# Concatenation of the dataframes with and without tags\n",
        "df_balanced=pd.concat([with_tag_df, no_tag_df])\n",
        "y_balanced=pd.concat([with_tag_y, no_tag_y])\n",
        "\n",
        "# Shuffling of the rows so we don't have all no tag rows at the end\n",
        "shuffled_idx=df_balanced.sample(frac=1, random_state=42).index\n",
        "df_balanced=df_balanced.loc[shuffled_idx].reset_index(drop=True)\n",
        "y_balanced=y_balanced.loc[shuffled_idx].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nBg2yde_q5w"
      },
      "outputs": [],
      "source": [
        "# Only keeping useful features useless columns\n",
        "X=df_balanced['prob_desc_description']\n",
        "\n",
        "# Train/test/val split\n",
        "X_train_val, X_test, y_train_val, y_test=train_test_split(X,y_balanced, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val=train_test_split(X_train_val,y_train_val, test_size=0.13, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzU557iL_rla"
      },
      "source": [
        "# Pretrained model and tokenizer import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3HKPqqSkOqy"
      },
      "outputs": [],
      "source": [
        "model_path=\"bert-base-uncased\"\n",
        "\n",
        "tokenizer=AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "id2label={index:tag for index,tag in enumerate(tags_to_keep)}\n",
        "label2id={tag: index for index, tag in enumerate(tags_to_keep)}\n",
        "model=AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_path,\n",
        "    num_labels=len(tags_to_keep),\n",
        "    problem_type=\"multi_label_classification\",\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")\n",
        "\n",
        "# Freezing base model parameters\n",
        "for name, param in model.base_model.named_parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Unfreezing the last four encoder layers\n",
        "for layer_idx in [8,9,10, 11]:\n",
        "    for param in model.base_model.encoder.layer[layer_idx].parameters():\n",
        "        param.requires_grad = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKr61WcB6VT9"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHmrKvLXmQa9"
      },
      "outputs": [],
      "source": [
        "def tokenization_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\")\n",
        "\n",
        "train_dataset=Dataset.from_dict({\"text\": X_train.tolist(), \"labels\": y_train.values.tolist()})\n",
        "val_dataset=Dataset.from_dict({\"text\":X_val.tolist(), \"labels\":y_val.values.tolist()})\n",
        "test_dataset = Dataset.from_dict({\"text\": X_test.tolist(), \"labels\": y_test.values.tolist()})\n",
        "\n",
        "train_dataset=train_dataset.map(tokenization_function, batched=True)\n",
        "val_dataset=val_dataset.map(tokenization_function, batched=True)\n",
        "test_dataset=test_dataset.map(tokenization_function, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynTdb2M46r7H"
      },
      "source": [
        "# Definition of the metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fav6_pumYkg"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    probabilities = 1/(1+np.exp(-predictions))\n",
        "    thresholds= np.round(np.arange(0.2,1,0.1),1) # We compute for different thresholds to find the best\n",
        "    metrics ={f\"f1_micro_{int(t*100)}\": f1_score(labels,(probabilities>=t).astype(int), average='micro', zero_division=0)for t in thresholds}\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0a7SJ4B6q7S"
      },
      "source": [
        "# Modification of the loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CapMFqtQMs84"
      },
      "outputs": [],
      "source": [
        "# Computing  class weights\n",
        "tag_count={}\n",
        "for tag in y.columns:\n",
        "    tag_count[tag]=y[tag].sum()\n",
        "class_weights=[(y.shape[0]-count)/count for tag, count in tag_count.items()]\n",
        "\n",
        "# Changing the loss function to handle class imbalance\n",
        "class WeightedTrainer(Trainer):\n",
        "    def __init__(self, class_weights, focal_alpha=0.25, focal_gamma=2.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.class_weights=torch.tensor(class_weights, dtype=torch.float32)\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        labels=inputs[\"labels\"]\n",
        "        outputs=model(**inputs)\n",
        "        logits=outputs[\"logits\"]\n",
        "        loss=torch.nn.functional.binary_cross_entropy_with_logits(logits, labels, pos_weight=self.class_weights.to(logits.device), reduction='mean')\n",
        "        return (loss, outputs) if return_outputs else loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNT07Agjsgir"
      },
      "source": [
        "# Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUd2VhZCmZcP"
      },
      "outputs": [],
      "source": [
        "os.environ[\"WANDB_DISABLED\"]=\"true\"\n",
        "\n",
        "# Hyperparameters\n",
        "lr=2e-5\n",
        "batch_size=16\n",
        "num_epochs=10\n",
        "\n",
        "\n",
        "training_args=TrainingArguments(\n",
        "    output_dir=\"bert-codeforces-tags\",\n",
        "    learning_rate=lr,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=num_epochs,\n",
        "    logging_strategy=\"epoch\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1_micro_50\",\n",
        "    greater_is_better=True,\n",
        "    weight_decay=0.01 # Regularization\n",
        ")\n",
        "\n",
        "\n",
        "trainer=WeightedTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    class_weights=class_weights,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)] # Early stopping\n",
        ")\n",
        "\n",
        "\n",
        "trainer.train()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
